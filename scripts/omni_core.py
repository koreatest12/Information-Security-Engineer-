import sqlite3
import os
import datetime
import requests
import psutil
import feedparser # RSS íŒŒì‹±
import pandas as pd
from sklearn.ensemble import IsolationForest

# ì„¤ì •
DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_master.db')
DASH_PATH = os.getenv('DASHBOARD_FILE', 'data/omni_dashboard.md')

class NewsAggregator:
    """IT ë° AI ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    def __init__(self):
        # ê³µì‹ ë ¥ ìˆëŠ” í…Œí¬ ë‰´ìŠ¤ RSS í”¼ë“œ ëª©ë¡
        self.feeds = [
            "https://techcrunch.com/category/artificial-intelligence/feed/", # TechCrunch AI
            "https://www.wired.com/feed/category/science/latest/rss", # Wired Science/AI
            "https://feeds.feedburner.com/TheHackersNews", # Security
            "https://openai.com/blog/rss.xml" # OpenAI Blog
        ]
        self.keywords = ['AI', 'GPT', 'LLM', 'Generative', 'Nvidia', 'Data', 'Cyber', 'Cloud', 'Python', 'Model']

    def fetch_news(self, limit=5):
        news_items = []
        try:
            for url in self.feeds:
                feed = feedparser.parse(url)
                for entry in feed.entries[:5]: # ê° í”¼ë“œë‹¹ ìµœì‹  5ê°œ ìŠ¤ìº”
                    title = entry.title
                    link = entry.link
                    # ë‚ ì§œ ì²˜ë¦¬ (ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„)
                    published = getattr(entry, 'published', datetime.datetime.now().strftime('%Y-%m-%d'))[:10]
                    
                    # í‚¤ì›Œë“œ í•„í„°ë§ (ê´€ì‹¬ ì£¼ì œë§Œ)
                    # ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, AI ì „ìš© í”¼ë“œì¸ ê²½ìš°
                    if any(k.lower() in title.lower() for k in self.keywords) or "artificial-intelligence" in url:
                        news_items.append({'date': published, 'source': feed.feed.title, 'title': title, 'link': link})
        except Exception as e:
            print(f"âš ï¸ News Fetch Error: {e}")
            return []

        # ë‚ ì§œìˆœ ì •ë ¬ í›„ ìƒìœ„ Nê°œ ë°˜í™˜
        news_items.sort(key=lambda x: x['date'], reverse=True)
        return news_items[:limit]

class SystemMonitor:
    @staticmethod
    def get_metrics():
        return psutil.cpu_percent(interval=1), psutil.virtual_memory().percent, psutil.disk_usage('/').percent

    @staticmethod
    def get_geo_info():
        try:
            r = requests.get('https://ipinfo.io/json', timeout=3).json()
            return r.get('ip', 'Unknown'), r.get('city', 'Unknown'), r.get('country', 'Unknown')
        except: return "127.0.0.1", "Localhost", "N/A"

class ExternalFetcher:
    @staticmethod
    def get_bitcoin():
        try:
            r = requests.get("https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd", headers={'User-Agent': 'Bot'}, timeout=3)
            return r.json()['bitcoin']['usd']
        except: return 97500.0

class DashboardGenerator:
    def __init__(self, conn):
        self.conn = conn

    def draw_gauge(self, val):
        fill = int((val / 100) * 10)
        return "â–ˆ" * fill + "â–‘" * (10 - fill)

    def generate(self, sys, geo, btc, news_list):
        cpu, ram, disk = sys
        ip, city, country = geo
        
        with open(DASH_PATH, 'w', encoding='utf-8') as f:
            f.write(f"# ğŸ“° Grand Ops News-Commander\n")
            f.write(f"> **Report Time:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (KST) | **Location:** {city}, {country}\n\n")

            # 1. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì„¹ì…˜
            f.write("### ğŸ–¥ï¸ System & Resource Status\n")
            f.write(f"| Metric | Usage | Gauge | Status |\n|---|---|---|---|\n")
            f.write(f"| **CPU** | {cpu}% | `{self.draw_gauge(cpu)}` | {'ğŸŸ¢ Optimal' if cpu < 70 else 'ğŸ”´ High'} |\n")
            f.write(f"| **RAM** | {ram}% | `{self.draw_gauge(ram)}` | {'ğŸŸ¢ Good' if ram < 80 else 'ğŸŸ¡ Warning'} |\n")
            f.write(f"| **BTC** | ${btc:,.2f} | - | Global Index |\n\n")

            # 2. [NEW] AI & IT ë‰´ìŠ¤ ì„¹ì…˜
            f.write("### ğŸ¤– Global AI & IT Trends (Live Briefing)\n")
            if news_list:
                f.write(f"| Date | Source | Headline (Click to Read) |\n|---|---|---|\n")
                for n in news_list:
                    # ì†ŒìŠ¤ëª… ê°„ì†Œí™”
                    src = n['source'].replace('TechCrunch', 'TC').replace('The Hacker News', 'HackerNews').split(' ')[0]
                    f.write(f"| {n['date']} | **{src}** | [{n['title']}]({n['link']}) |\n")
            else:
                f.write("> ğŸ“­ No major AI updates in the last hour.\n")
            
            f.write("\n---\n*Dashboard generated by Grand Ops AI Engine v23.0*")

def main():
    if not os.path.exists("data"): os.makedirs("data")
    conn = sqlite3.connect(DB_PATH)
    
    # ëª¨ë“ˆ ì‹¤í–‰
    sys_mon = SystemMonitor()
    metrics = sys_mon.get_metrics()
    geo = sys_mon.get_geo_info()
    
    ext = ExternalFetcher()
    btc = ext.get_bitcoin()
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘
    print("ğŸ“¡ Scanning Global Tech News...")
    aggregator = NewsAggregator()
    news = aggregator.fetch_news(limit=7) # ìƒìœ„ 7ê°œ ë‰´ìŠ¤
    
    # ëŒ€ì‹œë³´ë“œ ìƒì„±
    dash = DashboardGenerator(conn)
    dash.generate(metrics, geo, btc, news)
    
    conn.close()
    print("âœ… Dashboard with News Generated.")

if __name__ == "__main__":
    main()
