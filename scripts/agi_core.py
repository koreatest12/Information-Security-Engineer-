import sqlite3
import os
import datetime
import random
import json
import pandas as pd
import numpy as np
from scipy import stats

# ì„¤ì •
DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_brain.db')
REPORT_PATH = os.getenv('REPORT_PATH', 'data/agi_intelligence_report.md')

class KnowledgeBrain:
    """ì§€ì‹ í•™ìŠµ ë° ê¸°ì–µ ë‹´ë‹¹"""
    def __init__(self, conn):
        self.conn = conn
        
    def learn_patterns(self, df):
        """ë°ì´í„°ë¡œë¶€í„° í†µê³„ì  ì§€ì‹ì„ ì¶”ì¶œí•˜ì—¬ í•™ìŠµ(ì €ì¥)"""
        if df.empty: return
        
        # í•™ìŠµ: ì‹¤í–‰ ì‹œê°„ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ 'ì§€ì‹'ìœ¼ë¡œ ì €ì¥
        avg_time = np.mean(df['execution_time'])
        std_dev = np.std(df['execution_time'])
        
        cursor = self.conn.cursor()
        # ì§€ì‹ í…Œì´ë¸”ì— 'ExecutionTime_Baseline'ì´ë¼ëŠ” ê°œë…ì„ ì—…ë°ì´íŠ¸
        cursor.execute('''
            INSERT OR REPLACE INTO knowledge_base (concept, val_mean, val_std, last_learned)
            VALUES (?, ?, ?, ?)
        ''', ('EXECUTION_TIME', avg_time, std_dev, datetime.datetime.now()))
        self.conn.commit()
        return avg_time, std_dev

class LogicJudge:
    """ì •ì˜¤ íŒë‹¨ ë° ì˜¤ë¥˜ ê²€ì¦ ë‹´ë‹¹"""
    def __init__(self, conn):
        self.conn = conn
        
    def judge_truth(self, val, concept):
        """ì €ì¥ëœ ì§€ì‹(Baseline)ê³¼ ë¹„êµí•˜ì—¬ ì°¸/ê±°ì§“ íŒë‹¨"""
        cursor = self.conn.cursor()
        cursor.execute("SELECT val_mean, val_std FROM knowledge_base WHERE concept=?", (concept,))
        row = cursor.fetchone()
        
        if not row: return "UNKNOWN" # ì§€ì‹ ë¶€ì¡±
        
        mean, std = row
        # ì •ì˜¤ íŒë‹¨ ë¡œì§: í‰ê· ì—ì„œ 3í‘œì¤€í¸ì°¨ ì´ìƒ ë²—ì–´ë‚˜ë©´ 'ì˜¤ë¥˜(False)'ë¡œ íŒë‹¨
        z_score = abs((val - mean) / (std + 1e-9)) # 0ë‚˜ëˆ„ê¸° ë°©ì§€
        
        if z_score > 3:
            return "FALSE (Error/Anomaly)"
        else:
            return "TRUE (Normal)"

class Calculator:
    """ê³ ë„ ê³„ì‚° ë° ìˆ˜ì¹˜ í•´ì„ ë‹´ë‹¹"""
    @staticmethod
    def compute_metrics(df):
        if df.empty: return {}
        
        # Numpy/Scipyë¥¼ í™œìš©í•œ ë³µí•© ì—°ì‚°
        metrics = {
            "total_ops": len(df),
            "success_rate": np.mean(df['status'] == 'SUCCESS') * 100,
            "avg_exec_time": np.mean(df['execution_time']),
            "p95_exec_time": np.percentile(df['execution_time'], 95), # 95ë°±ë¶„ìœ„ìˆ˜
            "variance": np.var(df['execution_time']), # ë¶„ì‚°
            "cv": stats.variation(df['execution_time']) # ë³€ë™ ê³„ìˆ˜
        }
        return metrics

def init_system():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # ë°ì´í„° í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS ops_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            operation TEXT,
            status TEXT,
            execution_time REAL,
            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # ì§€ì‹ ì €ì¥ì†Œ (Knowledge Base) í…Œì´ë¸”
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS knowledge_base (
            concept TEXT PRIMARY KEY,
            val_mean REAL,
            val_std REAL,
            last_learned TIMESTAMP
        )
    ''')
    
    # (ì‹œë®¬ë ˆì´ì…˜) ë°ì´í„° ìƒì„±
    ops = ['DB_SYNC', 'AUTH_CHECK', 'DATA_PROCESS']
    statuses = ['SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE'] # 75% ì„±ê³µë¥ 
    
    new_logs = []
    for _ in range(50):
        op = random.choice(ops)
        st = random.choice(statuses)
        # ì •ìƒì€ 10~50, ê°€ë” ì˜¤ë¥˜ë¡œ 500~1000 ë°œìƒ
        time_val = np.random.normal(30, 5) if st == 'SUCCESS' else np.random.normal(600, 50)
        new_logs.append((op, st, time_val))
        
    cursor.executemany("INSERT INTO ops_logs (operation, status, execution_time) VALUES (?, ?, ?)", new_logs)
    conn.commit()
    return conn

def main():
    print("ğŸ§  AGI Core Starting...")
    if not os.path.exists("data"): os.makedirs("data")
    
    conn = init_system()
    
    # ë°ì´í„° ë¡œë“œ
    df = pd.read_sql_query("SELECT * FROM ops_logs", conn)
    
    # 1. [ì§€ëŠ¥] ì§€ì‹ í•™ìŠµ (Learning)
    brain = KnowledgeBrain(conn)
    mean, std = brain.learn_patterns(df)
    print(f"ğŸ“˜ Knowledge Learned: Mean={mean:.2f}, Std={std:.2f}")
    
    # 2. [ê³„ì‚°] ê³ ë„ ì—°ì‚° (Calculation)
    calc = Calculator()
    metrics = calc.compute_metrics(df)
    print(f"ğŸ§® Calculation Results: {metrics}")
    
    # 3. [íŒë‹¨] ì •ì˜¤ íŒë‹¨ (Judgment)
    judge = LogicJudge(conn)
    # ê°€ì¥ ìµœê·¼ ë¡œê·¸ í•˜ë‚˜ë¥¼ ê°€ì ¸ì™€ì„œ íŒë‹¨ í…ŒìŠ¤íŠ¸
    latest_val = df.iloc[-1]['execution_time']
    verdict = judge.judge_truth(latest_val, 'EXECUTION_TIME')
    print(f"âš–ï¸ Judgment on latest value ({latest_val:.2f}): {verdict}")

    # ë¦¬í¬íŠ¸ ì‘ì„±
    with open(REPORT_PATH, 'w') as f:
        f.write("# ğŸ§  AGI Intelligence Report\n")
        f.write(f"**Timestamp:** {datetime.datetime.now()}\n\n")
        
        f.write("## 1. ğŸ“˜ Knowledge Base (Learning)\n")
        f.write(f"- **Learned Baseline Mean:** {mean:.4f} ms\n")
        f.write(f"- **Learned Baseline StdDev:** {std:.4f}\n\n")
        
        f.write("## 2. ğŸ§® Advanced Calculations\n")
        f.write(f"- **Success Rate:** {metrics['success_rate']:.2f}%\n")
        f.write(f"- **95th Percentile Time:** {metrics['p95_exec_time']:.2f} ms\n")
        f.write(f"- **Variance (Volatility):** {metrics['variance']:.2f}\n\n")
        
        f.write("## 3. âš–ï¸ Logic Judgment (Verification)\n")
        f.write(f"- **Test Value:** {latest_val:.2f}\n")
        f.write(f"- **AI Verdict:** **{verdict}**\n")
        
    conn.close()

if __name__ == "__main__":
    main()
