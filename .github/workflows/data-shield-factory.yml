name: ğŸ”’ Data Shield Workflow Factory

on:
  schedule:
    - cron: '5 */6 * * *'
  workflow_dispatch:

permissions:
  contents: write
  security-events: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  generate-data-shield-workflows:
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ§° Prepare workspace
        run: |
          mkdir -p resources/workflows/data_shield
          echo "â±ï¸ Starting bulk generation: Server Upgrade, Encryption, DLP, and Full DB Ops"

      - name: ğŸ›¡ï¸ Generate Full Stack Templates
        shell: bash
        run: |
          # 1ë¶€í„° 25ê¹Œì§€ ë°˜ë³µí•˜ë©° SQL, DDL, Index ê¸°ëŠ¥ì´ í¬í•¨ëœ ì›Œí¬í”Œë¡œìš° ëŒ€ëŸ‰ ìƒì„±
          for i in $(seq -w 1 25); do
            cat > resources/workflows/data_shield/data_shield_workflow_${i}.yml <<TEMPLATE
          version: "1.3"
          name: "Data Shield Workflow ${i}"
          description: |
            Auto-generated workflow including Server Upgrade, Security Ops,
            and Advanced Database Lifecycle (DDL, SQL, Indexing) for batch ${i}.
          metadata:
            owner: data-engineering
            classification: confidential
            rotation_window_hours: 12
          stages:
            # 1. ì„œë²„ ìœ ì§€ë³´ìˆ˜
            - id: server_maintenance
              name: Server Security Upgrade & Patch
              tasks:
                - action: system.package_update
                  target: os_packages
                  security_only: true
                - action: shield.agent_upgrade
                  channel: stable
                  version_constraint: ">= 2.5.0"

            # 2. ë°ì´í„° ì•”í˜¸í™”
            - id: encrypt_content
              name: AES-256 Encrypt Content
              tasks:
                - action: crypto.encrypt
                  algorithm: aes-256-gcm
                  key_ref: secrets.KMS_PRIMARY_KEY
                  iv_strategy: random_96bit
                  inputs:
                    - source: artifacts/raw_payload_${i}.json
                      target: vault/encrypted/payload_${i}.bin

            # 3. ë°ì´í„° ìœ ì¶œ ë°©ì§€
            - id: outbound_guard
              name: DLP Egress Control
              tasks:
                - action: dlp.scan
                  modes: [pii, secrets, credentials]
                  block_on_match: true
                  destinations: [s3, ftp, http]

            # 4. ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ìƒëª…ì£¼ê¸° (DDL -> SQL -> Index)
            - id: database_lifecycle
              name: Advanced DB Operations
              tasks:
                # [DDL] í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ì˜
                - action: database.ddl_execute
                  engine: sqlite
                  description: "Define Schema for Batch ${i}"
                  script: |
                    CREATE TABLE IF NOT EXISTS access_log_${i} (
                      log_id INTEGER PRIMARY KEY AUTOINCREMENT,
                      query_type TEXT NOT NULL,
                      timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    );
                    CREATE TABLE IF NOT EXISTS secure_dataset_${i} (
                      record_id TEXT PRIMARY KEY,
                      payload_ciphertext BLOB,
                      payload_hash TEXT
                    );

                # [SQL Query] ë°ì´í„° ì¡°ì‘
                - action: database.sql_execute
                  engine: sqlite
                  description: "Insert Audit Log and Verify Data"
                  queries:
                    - "INSERT INTO access_log_${i} (query_type) VALUES ('BATCH_START');"
                    - "DELETE FROM secure_dataset_${i} WHERE record_id IS NULL;"
                    - "SELECT count(*) FROM access_log_${i} WHERE timestamp > date('now', '-1 day');"

                # [DB Index] ì„±ëŠ¥ ìµœì í™” ì¸ë±ìŠ¤
                - action: database.create_index
                  engine: sqlite
                  table: secure_dataset_${i}
                  index: idx_secure_dataset_${i}_hash
                  columns: [payload_hash]
                  unique: true
                  method: b-tree

                - action: database.create_index
                  engine: sqlite
                  table: access_log_${i}
                  index: idx_access_log_${i}_time
                  columns: [timestamp]
                  unique: false
          TEMPLATE
          done
          echo "âœ… Generated 25 workflows with full stack capabilities"

      - name: âœ… Commit and Sync changes
        run: |
          git config --global user.name "data-shield-bot"
          git config --global user.email "bot@datashield.io"
          
          # ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§•
          git add resources/workflows/data_shield
          
          # ë³€ê²½ì‚¬í•­ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ, ìˆìœ¼ë©´ ì»¤ë°‹
          if git diff --cached --quiet; then
            echo "No updates to commit"
            exit 0
          fi
          
          git commit -m "chore: update data shield workflows with full db features"

          # [CRITICAL FIX] Push ì „ ìµœì‹  ë³€ê²½ì‚¬í•­ ë‹¹ê²¨ì˜¤ê¸° (Rebase)
          # ì›ê²© ì €ì¥ì†Œì™€ ë¡œì»¬ ì €ì¥ì†Œì˜ ë™ê¸°í™”ë¥¼ ë§ì¶° non-fast-forward ì—ëŸ¬ ë°©ì§€
          echo "ğŸ”„ Pulling latest changes from remote..."
          git pull --rebase origin ${{ github.ref_name }}
          
      - name: ğŸš€ Push updates
        run: |
          # ë™ê¸°í™” ì™„ë£Œ í›„ Push
          git push origin ${{ github.ref_name }}
