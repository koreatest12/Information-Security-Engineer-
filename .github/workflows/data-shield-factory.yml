name: ğŸ”’ Data Shield Workflow Factory

on:
  schedule:
    # [ìˆ˜ì •] 30ë¶„ ì£¼ê¸°ë¡œ íŒ©í† ë¦¬ ì‹¤í–‰ (ë§¤ ì‹œê°„ 0ë¶„, 30ë¶„)
    - cron: '0,30 * * * *'
  workflow_dispatch:

permissions:
  contents: write
  security-events: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  generate-data-shield-workflows:
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ§° Prepare workspace
        run: |
          mkdir -p resources/workflows/data_shield
          echo "â±ï¸ Starting bulk generation: Server Upgrade, Encryption, DLP, and Full DB Ops"

      - name: ğŸ›¡ï¸ Generate Full Stack Templates
        shell: bash
        run: |
          # 1ë¶€í„° 25ê¹Œì§€ ë°˜ë³µí•˜ë©° ì›Œí¬í”Œë¡œìš° ëŒ€ëŸ‰ ìƒì„±
          for i in $(seq -w 1 25); do
            
            # ì§ìˆ˜/í™€ìˆ˜ ë²ˆí˜¸ì— ë”°ë¼ ìŠ¤ì¼€ì¤„ ì£¼ê¸° ë¶„ë¦¬ (ë¶€í•˜ ë¶„ì‚°)
            # ì§ìˆ˜ ë²ˆí˜¸ ì›Œí¬í”Œë¡œìš°: 1ì‹œê°„ ì£¼ê¸° (ë§¤ì‹œ ì •ê°)
            # í™€ìˆ˜ ë²ˆí˜¸ ì›Œí¬í”Œë¡œìš°: 30ë¶„ ì£¼ê¸° (ë§¤ì‹œ 15ë¶„, 45ë¶„)
            if (( i % 2 == 0 )); then
              CRON_SCHEDULE="0 * * * *"
              FREQ_DESC="Hourly (Every 1 hour)"
            else
              CRON_SCHEDULE="15,45 * * * *"
              FREQ_DESC="Every 30 minutes"
            fi

            cat > resources/workflows/data_shield/data_shield_workflow_${i}.yml <<TEMPLATE
          version: "1.4"
          name: "Data Shield Workflow ${i}"
          on:
            schedule:
              - cron: '${CRON_SCHEDULE}'
            workflow_dispatch:
            
          description: |
            Auto-generated workflow running ${FREQ_DESC}.
            Includes Server Upgrade, Security Ops, and Advanced Database Lifecycle.
            Batch ID: ${i}
          metadata:
            owner: data-engineering
            classification: confidential
            rotation_window_hours: 12
          stages:
            # 1. ì„œë²„ ìœ ì§€ë³´ìˆ˜
            - id: server_maintenance
              name: Server Security Upgrade & Patch
              tasks:
                - action: system.package_update
                  target: os_packages
                  security_only: true
                - action: shield.agent_upgrade
                  channel: stable
                  version_constraint: ">= 2.5.0"

            # 2. ë°ì´í„° ì•”í˜¸í™”
            - id: encrypt_content
              name: AES-256 Encrypt Content
              tasks:
                - action: crypto.encrypt
                  algorithm: aes-256-gcm
                  key_ref: secrets.KMS_PRIMARY_KEY
                  iv_strategy: random_96bit
                  inputs:
                    - source: artifacts/raw_payload_${i}.json
                      target: vault/encrypted/payload_${i}.bin

            # 3. ë°ì´í„° ìœ ì¶œ ë°©ì§€
            - id: outbound_guard
              name: DLP Egress Control
              tasks:
                - action: dlp.scan
                  modes: [pii, secrets, credentials]
                  block_on_match: true
                  destinations: [s3, ftp, http]

            # 4. ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ ìƒëª…ì£¼ê¸° (DDL -> SQL -> Index)
            - id: database_lifecycle
              name: Advanced DB Operations
              tasks:
                # [DDL] í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ì˜
                - action: database.ddl_execute
                  engine: sqlite
                  description: "Define Schema for Batch ${i}"
                  script: |
                    CREATE TABLE IF NOT EXISTS access_log_${i} (
                      log_id INTEGER PRIMARY KEY AUTOINCREMENT,
                      query_type TEXT NOT NULL,
                      timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
                    );
                    CREATE TABLE IF NOT EXISTS secure_dataset_${i} (
                      record_id TEXT PRIMARY KEY,
                      payload_ciphertext BLOB,
                      payload_hash TEXT
                    );

                # [SQL Query] ë°ì´í„° ì¡°ì‘
                - action: database.sql_execute
                  engine: sqlite
                  description: "Insert Audit Log and Verify Data"
                  queries:
                    - "INSERT INTO access_log_${i} (query_type) VALUES ('BATCH_START');"
                    - "DELETE FROM secure_dataset_${i} WHERE record_id IS NULL;"
                    - "SELECT count(*) FROM access_log_${i} WHERE timestamp > date('now', '-1 day');"

                # [DB Index] ì„±ëŠ¥ ìµœì í™” ì¸ë±ìŠ¤
                - action: database.create_index
                  engine: sqlite
                  table: secure_dataset_${i}
                  index: idx_secure_dataset_${i}_hash
                  columns: [payload_hash]
                  unique: true
                  method: b-tree

                - action: database.create_index
                  engine: sqlite
                  table: access_log_${i}
                  index: idx_access_log_${i}_time
                  columns: [timestamp]
                  unique: false
          TEMPLATE
          done
          echo "âœ… Generated 25 workflows with 30m/1h schedules"

      - name: âœ… Commit and Sync changes
        run: |
          git config --global user.name "data-shield-bot"
          git config --global user.email "bot@datashield.io"
          
          # ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§•
          git add resources/workflows/data_shield
          
          # ë³€ê²½ì‚¬í•­ ê²€ì‚¬
          if git diff --cached --quiet; then
            echo "No updates to commit"
            exit 0
          fi
          
          git commit -m "feat: update schedules to 30m and hourly intervals"

          # [CRITICAL FIX] Push ì „ ìµœì‹  ë³€ê²½ì‚¬í•­ ë‹¹ê²¨ì˜¤ê¸° (Rebase)
          echo "ğŸ”„ Pulling latest changes from remote..."
          git pull --rebase origin ${{ github.ref_name }}
          
      - name: ğŸš€ Push updates
        run: |
          git push origin ${{ github.ref_name }}
