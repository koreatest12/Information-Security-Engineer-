name: ğŸŒŒ Grand Ops Master-Universe v29 (All-in-One AI & News)

on:
  schedule:
    - cron: '*/30 * * * *' # 30ë¶„ ì£¼ê¸° í†µí•© ì‹¤í–‰
  workflow_dispatch:
    inputs:
      copilot_query:
        description: 'ğŸ’¬ AI Copilotì—ê²Œ ì§ˆë¬¸ (ì˜ˆ: "ì˜¤ëŠ˜ì˜ ë³´ì•ˆ ì´ìŠˆì™€ ì‹œìŠ¤í…œ ìƒíƒœëŠ”?")'
        required: false
        default: 'í˜„ì¬ ì‹œìŠ¤í…œ ìƒíƒœì™€ ì£¼ìš” êµ­ë‚´ì™¸ ë‰´ìŠ¤ë¥¼ ì¢…í•© ë¸Œë¦¬í•‘í•´ì¤˜.'

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  TZ: 'Asia/Seoul'
  DB_PATH: 'data/grand_ops_master.db'
  DASHBOARD_FILE: 'data/master_dashboard.md'
  USER_QUERY: ${{ inputs.copilot_query || 'ì¢…í•© ìƒí™© ë¸Œë¦¬í•‘ ìš”ì²­' }}
  ARTIFACT_PASSWORD: ${{ secrets.ARTIFACT_KEY || 'Master_Universe_2025' }}

permissions:
  contents: write

jobs:
  master-universe-engine:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ—ï¸ Initialize Master Environment
        run: |
          echo "ğŸŒŒ Booting Grand Ops Master-Universe..."
          mkdir -p data backup scripts dist
          python -m pip install --upgrade pip
          
          # [í†µí•© ì˜ì¡´ì„± ì„¤ì¹˜]
          # textblob: NLP, beautifulsoup4: í¬ë¡¤ë§, scikit-learn: AIë¶„ì„, feedparser: ë‰´ìŠ¤
          echo -e "requests\npandas\nnumpy\nscikit-learn\ntabulate\npsutil\nfeedparser\nbeautifulsoup4\ntextblob" > requirements.txt
          pip install -r requirements.txt
          python -m textblob.download_corpora

      - name: ğŸ§  Generate Master-Universe Script
        run: |
          cat <<'EOF' > scripts/master_universe_core.py
          import sqlite3
          import os
          import datetime
          import psutil
          import requests
          import feedparser
          from bs4 import BeautifulSoup
          import pandas as pd
          from textblob import TextBlob
          from sklearn.feature_extraction.text import TfidfVectorizer
          from sklearn.metrics.pairwise import cosine_similarity

          # ==========================================
          # âš™ï¸ CONFIGURATION
          # ==========================================
          DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_master.db')
          DASH_PATH = os.getenv('DASHBOARD_FILE', 'data/master_dashboard.md')
          USER_QUERY = os.getenv('USER_QUERY', '')

          # ==========================================
          # 1. HYPERSCALE SYSTEM MONITOR
          # ==========================================
          class HyperscaleMonitor:
              """ê°€ìƒí™”ëœ ëŒ€ìš©ëŸ‰ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
              def __init__(self):
                  self.v_cores = 128
                  self.v_ram_gb = 512
                  self.v_storage_tb = 1024

              def get_metrics(self):
                  real_cpu = psutil.cpu_percent()
                  real_ram = psutil.virtual_memory().percent
                  
                  return {
                      "cpu_load": real_cpu,
                      "ram_percent": real_ram,
                      "spec_cpu": f"{self.v_cores} vCores",
                      "spec_ram": f"{(real_ram/100)*self.v_ram_gb:.1f}/{self.v_ram_gb} GB",
                      "spec_disk": "1PB NVMe Pool"
                  }

          # ==========================================
          # 2. GLOBAL & KOREAN NEWS AGGREGATOR
          # ==========================================
          class GlobalNewsEngine:
              """êµ­ë‚´ì™¸ ë‰´ìŠ¤ í†µí•© ìˆ˜ì§‘"""
              def __init__(self):
                  self.feeds = {
                      "KR_NAVER": "https://news.naver.com/main/rss/rss_flash.nhn",
                      "KR_SECURITY": "https://www.boannews.com/media/news_rss.xml",
                      "KR_IT": "https://news.google.com/rss/search?q=IT+ì¸ê³µì§€ëŠ¥&hl=ko&gl=KR&ceid=KR:ko",
                      "US_TECH": "https://techcrunch.com/category/artificial-intelligence/feed/",
                      "US_SEC": "https://feeds.feedburner.com/TheHackersNews"
                  }
                  self.headers = {'User-Agent': 'Mozilla/5.0 (GrandOpsBot/1.0)'}

              def fetch_all(self):
                  news_data = {}
                  corpus = [] # AI í•™ìŠµìš© í…ìŠ¤íŠ¸
                  
                  for source, url in self.feeds.items():
                      entries = []
                      try:
                          f = feedparser.parse(url)
                          if not f.entries: # RSS ì‹¤íŒ¨ ì‹œ requests ì‹œë„
                              r = requests.get(url, headers=self.headers, timeout=5)
                              f = feedparser.parse(r.content)
                              
                          for e in f.entries[:3]: # ì†ŒìŠ¤ë‹¹ 3ê°œ
                              clean_title = e.title.replace("&quot;", "'").replace("<b>", "").replace("</b>", "")
                              entries.append({"title": clean_title, "link": e.link})
                              
                              # AI í•™ìŠµìš© ë°ì´í„° ì „ì²˜ë¦¬
                              tag = "êµ­ë‚´ë‰´ìŠ¤" if "KR" in source else "GlobalNews"
                              corpus.append(f"[{tag}] {clean_title}")
                      except: pass
                      news_data[source] = entries
                  
                  return news_data, corpus

          # ==========================================
          # 3. AI COGNITIVE COPILOT (RAG)
          # ==========================================
          class MasterCopilot:
              """ì‹œìŠ¤í…œ ìƒíƒœì™€ ë‰´ìŠ¤ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ ìƒì„±"""
              def __init__(self, news_corpus, sys_metrics):
                  self.knowledge_base = news_corpus
                  
                  # ì‹œìŠ¤í…œ ìƒíƒœë¥¼ ìì—°ì–´ë¡œ ë³€í™˜í•˜ì—¬ ì§€ì‹ì— ì¶”ê°€
                  sys_context = f"SYSTEM_METRICS: CPU Load {sys_metrics['cpu_load']}%, RAM Usage {sys_metrics['ram_percent']}%."
                  if sys_metrics['cpu_load'] < 50:
                      sys_context += " STATUS: Stable. Optimal for deployment."
                  else:
                      sys_context += " STATUS: Heavy Load. Auto-scaling recommended."
                  self.knowledge_base.append(sys_context)

              def generate_response(self, query):
                  if not self.knowledge_base: return "ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                  
                  # TF-IDF ë²¡í„°í™” ë° ìœ ì‚¬ë„ ê²€ìƒ‰
                  vectorizer = TfidfVectorizer()
                  tfidf_matrix = vectorizer.fit_transform(self.knowledge_base)
                  query_vec = vectorizer.transform([query])
                  
                  sim_scores = cosine_similarity(query_vec, tfidf_matrix).flatten()
                  top_indices = sim_scores.argsort()[:-4:-1] # ìƒìœ„ 3ê°œ
                  
                  context_found = False
                  response_lines = []
                  
                  for idx in top_indices:
                      if sim_scores[idx] > 0.05:
                          response_lines.append(f"- {self.knowledge_base[idx]}")
                          context_found = True
                  
                  timestamp = datetime.datetime.now().strftime("%H:%M")
                  final_res = f"### ğŸ¤– Master-Copilot Briefing ({timestamp})\n"
                  final_res += f"> **Q:** \"{query}\"\n\n"
                  
                  if context_found:
                      final_res += "**âœ… ë¶„ì„ëœ ì¸ì‚¬ì´íŠ¸:**\n" + "\n".join(response_lines)
                      final_res += "\n\n*ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ íŒë‹¨í•  ë•Œ, í˜„ì¬ ì‹œìŠ¤í…œ ë° ê´€ë ¨ ì´ìŠˆëŠ” ìœ„ì™€ ê°™ìŠµë‹ˆë‹¤.*"
                  else:
                      final_res += "âŒ ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ìˆ˜ì§‘ëœ ë°ì´í„°(ë‰´ìŠ¤/ë¡œê·¸)ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                      
                  return final_res

          # ==========================================
          # 4. DASHBOARD GENERATOR
          # ==========================================
          class DashboardEngine:
              def draw_bar(self, val):
                  fill = int((val/100)*15)
                  return "â–ˆ"*fill + "â–‘"*(15-fill)

              def create_dashboard(self, metrics, news, copilot_ans):
                  with open(DASH_PATH, 'w', encoding='utf-8') as f:
                      f.write(f"# ğŸŒŒ Grand Ops Master-Universe Dashboard\n")
                      f.write(f"> **System Time:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (KST)\n\n")

                      # Copilot
                      f.write(f"{copilot_ans}\n\n")
                      f.write("---\n")

                      # Hyperscale Specs
                      f.write(f"### âš¡ Hyperscale Resources (128-Core Cluster)\n")
                      f.write(f"| Resource | Specification | Usage | Visual |\n|---|---|---|---|\n")
                      f.write(f"| **vCPU** | `{metrics['spec_cpu']}` | {metrics['cpu_load']}% | `{self.draw_bar(metrics['cpu_load'])}` |\n")
                      f.write(f"| **Memory** | `{metrics['spec_ram']}` | {metrics['ram_percent']}% | `{self.draw_bar(metrics['ram_percent'])}` |\n")
                      f.write(f"| **Storage**| `{metrics['spec_disk']}` | Healthy | `{self.draw_bar(15)}` |\n\n")

                      # News Section
                      f.write(f"### ğŸ“° Global & Korean Newsroom\n")
                      
                      # í•œêµ­ ë‰´ìŠ¤
                      f.write(f"#### ğŸ‡°ğŸ‡· êµ­ë‚´ ì†ë³´ (Naver/Boan)\n")
                      for src in ["KR_NAVER", "KR_SECURITY"]:
                          if src in news:
                              for item in news[src]:
                                  f.write(f"- [{item['title']}]({item['link']})\n")
                      
                      # ê¸€ë¡œë²Œ ë‰´ìŠ¤
                      f.write(f"\n#### ğŸŒ Global Tech (TechCrunch/HackerNews)\n")
                      for src in ["US_TECH", "US_SEC"]:
                          if src in news:
                              for item in news[src]:
                                  f.write(f"- [{item['title']}]({item['link']})\n")
                      
                      f.write("\n---\n*Powered by Grand Ops Master Engine v29.0*")

          # ==========================================
          # ğŸš€ MAIN EXECUTION
          # ==========================================
          def main():
              if not os.path.exists("data"): os.makedirs("data")
              conn = sqlite3.connect(DB_PATH)
              
              # 1. ëª¨ë‹ˆí„°ë§
              monitor = HyperscaleMonitor()
              metrics = monitor.get_metrics()
              
              # 2. ë‰´ìŠ¤ ìˆ˜ì§‘
              news_engine = GlobalNewsEngine()
              news_data, corpus = news_engine.fetch_all()
              
              # 3. ë°ì´í„° ëˆ„ì  (DB)
              conn.execute("CREATE TABLE IF NOT EXISTS master_logs (id INTEGER PRIMARY KEY, cpu REAL, timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP)")
              conn.execute("INSERT INTO master_logs (cpu) VALUES (?)", (metrics['cpu_load'],))
              conn.commit()
              
              # 4. Copilot ë¶„ì„
              copilot = MasterCopilot(corpus, metrics)
              answer = copilot.generate_response(USER_QUERY)
              
              # 5. ëŒ€ì‹œë³´ë“œ ìƒì„±
              dash = DashboardEngine()
              dash.create_dashboard(metrics, news_data, answer)
              
              conn.close()
              print("âœ… Master-Universe All Tasks Completed.")

          if __name__ == "__main__":
              main()
          EOF

      - name: ğŸš€ Run Master Engine
        run: python scripts/master_universe_core.py

      # ê²°ê³¼ í™”ë©´ ì¶œë ¥
      - name: ğŸ“¢ Publish Master Dashboard
        run: cat "$DASHBOARD_FILE" >> $GITHUB_STEP_SUMMARY

      # ë³´ì•ˆ ë°±ì—… ë° ë™ê¸°í™”
      - name: ğŸ”’ Encrypt & Sync Data
        run: |
          zip -e -P "$ARTIFACT_PASSWORD" master_backup.zip data/*.md data/*.db
          
          git config --global user.name "Master-AI"
          git config --global user.email "master@grand-ops.ai"
          git config --global --add safe.directory $GITHUB_WORKSPACE
          
          [ -f "$DASHBOARD_FILE" ] && git add -f "$DASHBOARD_FILE"
          [ -f "$DB_PATH" ] && git add -f "$DB_PATH"
          git add -A
          
          if [ -z "$(git status --porcelain)" ]; then exit 0; fi
          git commit -m "master: unified engine execution & news sync [skip ci]"
          git push origin main || echo "Sync skipped"
