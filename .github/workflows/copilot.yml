name: ğŸ“° Grand Ops News-Commander v23 (AI & IT Briefing)

on:
  schedule:
    - cron: '*/20 * * * *' # ë‰´ìŠ¤ ìˆ˜ì§‘ì„ ìœ„í•´ 20ë¶„ ì£¼ê¸°
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  TZ: 'Asia/Seoul'
  DB_PATH: 'data/grand_ops_master.db'
  DASHBOARD_FILE: 'data/omni_dashboard.md'
  ARTIFACT_PASSWORD: ${{ secrets.ARTIFACT_KEY || 'News_Secure_2025' }}

permissions:
  contents: write

jobs:
  news-dashboard-engine:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: ğŸ—ï¸ Setup Intelligence Stack
        run: |
          echo "ğŸ“¡ Initializing News & Monitor Stack..."
          mkdir -p data backup scripts
          python -m pip install --upgrade pip
          # [í•µì‹¬] feedparser: RSS ë‰´ìŠ¤ ìˆ˜ì§‘ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
          echo -e "requests\npandas\nnumpy\nscikit-learn\ntabulate\npsutil\nfeedparser" > requirements.txt
          pip install -r requirements.txt

      # [Core] ì‹œìŠ¤í…œ ê°ì‹œ + ì™¸ë¶€ ë°ì´í„° + [NEW] ë‰´ìŠ¤ ìˆ˜ì§‘ í†µí•© ì—”ì§„
      - name: ğŸ§  Generate News-Commander Script
        run: |
          cat <<'EOF' > scripts/omni_core.py
          import sqlite3
          import os
          import datetime
          import requests
          import psutil
          import feedparser # RSS íŒŒì‹±
          import pandas as pd
          from sklearn.ensemble import IsolationForest

          # ì„¤ì •
          DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_master.db')
          DASH_PATH = os.getenv('DASHBOARD_FILE', 'data/omni_dashboard.md')
          
          class NewsAggregator:
              """IT ë° AI ê´€ë ¨ ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
              def __init__(self):
                  # ê³µì‹ ë ¥ ìˆëŠ” í…Œí¬ ë‰´ìŠ¤ RSS í”¼ë“œ ëª©ë¡
                  self.feeds = [
                      "https://techcrunch.com/category/artificial-intelligence/feed/", # TechCrunch AI
                      "https://www.wired.com/feed/category/science/latest/rss", # Wired Science/AI
                      "https://feeds.feedburner.com/TheHackersNews", # Security
                      "https://openai.com/blog/rss.xml" # OpenAI Blog
                  ]
                  self.keywords = ['AI', 'GPT', 'LLM', 'Generative', 'Nvidia', 'Data', 'Cyber', 'Cloud', 'Python', 'Model']

              def fetch_news(self, limit=5):
                  news_items = []
                  try:
                      for url in self.feeds:
                          feed = feedparser.parse(url)
                          for entry in feed.entries[:5]: # ê° í”¼ë“œë‹¹ ìµœì‹  5ê°œ ìŠ¤ìº”
                              title = entry.title
                              link = entry.link
                              # ë‚ ì§œ ì²˜ë¦¬ (ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„)
                              published = getattr(entry, 'published', datetime.datetime.now().strftime('%Y-%m-%d'))[:10]
                              
                              # í‚¤ì›Œë“œ í•„í„°ë§ (ê´€ì‹¬ ì£¼ì œë§Œ)
                              # ì œëª©ì— í‚¤ì›Œë“œê°€ ìˆê±°ë‚˜, AI ì „ìš© í”¼ë“œì¸ ê²½ìš°
                              if any(k.lower() in title.lower() for k in self.keywords) or "artificial-intelligence" in url:
                                  news_items.append({'date': published, 'source': feed.feed.title, 'title': title, 'link': link})
                  except Exception as e:
                      print(f"âš ï¸ News Fetch Error: {e}")
                      return []

                  # ë‚ ì§œìˆœ ì •ë ¬ í›„ ìƒìœ„ Nê°œ ë°˜í™˜
                  news_items.sort(key=lambda x: x['date'], reverse=True)
                  return news_items[:limit]

          class SystemMonitor:
              @staticmethod
              def get_metrics():
                  return psutil.cpu_percent(interval=1), psutil.virtual_memory().percent, psutil.disk_usage('/').percent

              @staticmethod
              def get_geo_info():
                  try:
                      r = requests.get('https://ipinfo.io/json', timeout=3).json()
                      return r.get('ip', 'Unknown'), r.get('city', 'Unknown'), r.get('country', 'Unknown')
                  except: return "127.0.0.1", "Localhost", "N/A"

          class ExternalFetcher:
              @staticmethod
              def get_bitcoin():
                  try:
                      r = requests.get("https://api.coingecko.com/api/v3/simple/price?ids=bitcoin&vs_currencies=usd", headers={'User-Agent': 'Bot'}, timeout=3)
                      return r.json()['bitcoin']['usd']
                  except: return 97500.0

          class DashboardGenerator:
              def __init__(self, conn):
                  self.conn = conn

              def draw_gauge(self, val):
                  fill = int((val / 100) * 10)
                  return "â–ˆ" * fill + "â–‘" * (10 - fill)

              def generate(self, sys, geo, btc, news_list):
                  cpu, ram, disk = sys
                  ip, city, country = geo
                  
                  with open(DASH_PATH, 'w', encoding='utf-8') as f:
                      f.write(f"# ğŸ“° Grand Ops News-Commander\n")
                      f.write(f"> **Report Time:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (KST) | **Location:** {city}, {country}\n\n")

                      # 1. ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì„¹ì…˜
                      f.write("### ğŸ–¥ï¸ System & Resource Status\n")
                      f.write(f"| Metric | Usage | Gauge | Status |\n|---|---|---|---|\n")
                      f.write(f"| **CPU** | {cpu}% | `{self.draw_gauge(cpu)}` | {'ğŸŸ¢ Optimal' if cpu < 70 else 'ğŸ”´ High'} |\n")
                      f.write(f"| **RAM** | {ram}% | `{self.draw_gauge(ram)}` | {'ğŸŸ¢ Good' if ram < 80 else 'ğŸŸ¡ Warning'} |\n")
                      f.write(f"| **BTC** | ${btc:,.2f} | - | Global Index |\n\n")

                      # 2. [NEW] AI & IT ë‰´ìŠ¤ ì„¹ì…˜
                      f.write("### ğŸ¤– Global AI & IT Trends (Live Briefing)\n")
                      if news_list:
                          f.write(f"| Date | Source | Headline (Click to Read) |\n|---|---|---|\n")
                          for n in news_list:
                              # ì†ŒìŠ¤ëª… ê°„ì†Œí™”
                              src = n['source'].replace('TechCrunch', 'TC').replace('The Hacker News', 'HackerNews').split(' ')[0]
                              f.write(f"| {n['date']} | **{src}** | [{n['title']}]({n['link']}) |\n")
                      else:
                          f.write("> ğŸ“­ No major AI updates in the last hour.\n")
                      
                      f.write("\n---\n*Dashboard generated by Grand Ops AI Engine v23.0*")

          def main():
              if not os.path.exists("data"): os.makedirs("data")
              conn = sqlite3.connect(DB_PATH)
              
              # ëª¨ë“ˆ ì‹¤í–‰
              sys_mon = SystemMonitor()
              metrics = sys_mon.get_metrics()
              geo = sys_mon.get_geo_info()
              
              ext = ExternalFetcher()
              btc = ext.get_bitcoin()
              
              # ë‰´ìŠ¤ ìˆ˜ì§‘
              print("ğŸ“¡ Scanning Global Tech News...")
              aggregator = NewsAggregator()
              news = aggregator.fetch_news(limit=7) # ìƒìœ„ 7ê°œ ë‰´ìŠ¤
              
              # ëŒ€ì‹œë³´ë“œ ìƒì„±
              dash = DashboardGenerator(conn)
              dash.generate(metrics, geo, btc, news)
              
              conn.close()
              print("âœ… Dashboard with News Generated.")

          if __name__ == "__main__":
              main()
          EOF

      - name: ğŸš€ Run News-Commander
        run: python scripts/omni_core.py

      # [í•µì‹¬] GitHub Actions Summary ì¶œë ¥
      - name: ğŸ“¢ Publish Briefing
        run: |
          cat "$DASHBOARD_FILE" >> $GITHUB_STEP_SUMMARY

      - name: ğŸ”’ Encrypt & Upload
        run: |
          zip -e -P "$ARTIFACT_PASSWORD" news_dashboard.zip data/*.md data/*.db
      
      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: Intelligence-Bundle
          path: news_dashboard.zip

      - name: ğŸ”„ Sync Intelligence
        run: |
          git config --global user.name "News-Bot"
          git config --global user.email "news@grand-ops.ai"
          git config --global --add safe.directory $GITHUB_WORKSPACE
          
          [ -f "$DASHBOARD_FILE" ] && git add -f "$DASHBOARD_FILE"
          [ -f "$DB_PATH" ] && git add -f "$DB_PATH"
          git add -A
          
          if [ -z "$(git status --porcelain)" ]; then exit 0; fi
          git commit -m "dashboard: ai news & metrics update [skip ci]"
          git push origin main || echo "Sync skipped"
