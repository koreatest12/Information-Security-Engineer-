name: üèóÔ∏è Grand Ops Mega-Infrastructure v31 (Mass Install & Upgrade)

on:
  schedule:
    - cron: '*/30 * * * *' # 30Î∂Ñ Ï£ºÍ∏∞
  workflow_dispatch:
    inputs:
      copilot_query:
        description: 'üí¨ AIÏóêÍ≤å ÏßàÎ¨∏'
        required: false
        default: 'Ï†ÑÏ≤¥ ÏÑúÎ≤Ñ Ïù∏ÌîÑÎùº ÏÉÅÌÉúÏôÄ Í∏àÏúµ Îâ¥Ïä§ Î∏åÎ¶¨ÌïëÌï¥Ï§ò.'

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  TZ: 'Asia/Seoul'
  DB_PATH: 'data/grand_ops_mega.db'
  DASHBOARD_FILE: 'data/mega_dashboard.md'
  USER_QUERY: ${{ inputs.copilot_query || 'Ïù∏ÌîÑÎùº Î∞è Í∏àÏúµ Ï¢ÖÌï© Î∏åÎ¶¨Ìïë' }}
  ARTIFACT_PASSWORD: ${{ secrets.ARTIFACT_KEY || 'Mega_Infra_2025' }}

permissions:
  contents: write

jobs:
  mega-infra-engine:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # [NEW] 1. ÎåÄÍ∑úÎ™® ÏÑúÎ≤Ñ ÏÑ§Ïπò Î∞è ÏóÖÍ∑∏Î†àÏù¥Îìú (Mass Install & Upgrade)
      - name: üèóÔ∏è Provision Server Farm & Auto-Upgrade
        run: |
          echo "üöÄ Starting Mass Provisioning..."
          
          # 1) ÏãúÏä§ÌÖú Ìå®ÌÇ§ÏßÄ Î¶¨Ïä§Ìä∏ ÏóÖÎç∞Ïù¥Ìä∏
          sudo apt-get update
          
          # 2) [Upgrade] Î≥¥Ïïà Ìå®Ïπò Î∞è Ìå®ÌÇ§ÏßÄ ÏóÖÍ∑∏Î†àÏù¥Îìú
          echo "üîÑ Running Auto-Upgrade Sequence..."
          sudo apt-get dist-upgrade -y
          
          # 3) [Install] ÏóîÌÑ∞ÌîÑÎùºÏù¥Ï¶àÍ∏â ÏÑúÎ≤Ñ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ ÎåÄÎüâ ÏÑ§Ïπò
          echo "üì¶ Installing Enterprise Services..."
          # Nginx(Ïõπ), Redis(Ï∫êÏãú), Postgres(DB), ClamAV(Î∞±Ïã†), Prometheus(Î™®ÎãàÌÑ∞ÎßÅ)
          sudo apt-get install -y nginx redis-tools postgresql-client clamav clamav-daemon prometheus-node-exporter
          
          echo "‚úÖ Server Farm Provisioning Complete."

      - name: üèóÔ∏è Initialize Python Stack
        run: |
          mkdir -p data backup scripts dist
          python -m pip install --upgrade pip
          # ÏùòÏ°¥ÏÑ± ÏÑ§Ïπò (Í∏àÏúµ/Îâ¥Ïä§/ÏãúÏä§ÌÖú ÌÜµÌï©)
          echo -e "requests\npandas\nnumpy\nscikit-learn\ntabulate\npsutil\nfeedparser\nbeautifulsoup4\ntextblob" > requirements.txt
          pip install -r requirements.txt
          python -m textblob.download_corpora

      - name: üß† Generate Mega-Core Script
        run: |
          cat <<'EOF' > scripts/mega_core.py
          import sqlite3
          import os
          import datetime
          import psutil
          import requests
          import subprocess
          import feedparser
          from bs4 import BeautifulSoup
          import pandas as pd
          from sklearn.feature_extraction.text import TfidfVectorizer
          from sklearn.metrics.pairwise import cosine_similarity

          # ==========================================
          # ‚öôÔ∏è CONFIGURATION
          # ==========================================
          DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_mega.db')
          DASH_PATH = os.getenv('DASHBOARD_FILE', 'data/mega_dashboard.md')
          USER_QUERY = os.getenv('USER_QUERY', '')

          # ==========================================
          # 1. INFRA MANAGER (ÏÑúÎ≤Ñ ÏÉÅÌÉú Ï†êÍ≤Ä)
          # ==========================================
          class ServerFarmManager:
              """ÏÑ§ÏπòÎêú ÏÑúÎ≤Ñ ÏÜåÌîÑÌä∏Ïõ®Ïñ¥ Î≤ÑÏ†Ñ Î∞è ÏÉÅÌÉú Ï†êÍ≤Ä"""
              def check_version(self, cmd):
                  try:
                      # Î≤ÑÏ†Ñ ÌôïÏù∏ Î™ÖÎ†πÏñ¥ Ïã§Ìñâ
                      output = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
                      return output.decode('utf-8').split('\n')[0].strip()
                  except:
                      return "Not Found / Error"

              def get_farm_status(self):
                  # Í∞Å ÏÑúÎπÑÏä§Î≥Ñ Î≤ÑÏ†Ñ Ï≤¥ÌÅ¨ Î™ÖÎ†πÏñ¥
                  services = {
                      "Nginx (Web)": "nginx -v",
                      "Redis (Cache)": "redis-cli --version",
                      "PostgreSQL (DB)": "psql --version",
                      "ClamAV (Security)": "clamscan --version",
                      "Prometheus (Metrics)": "prometheus-node-exporter --version"
                  }
                  
                  status_report = []
                  for name, cmd in services.items():
                      ver = self.check_version(cmd)
                      status = "üü¢ Active" if "Error" not in ver else "üî¥ Error"
                      status_report.append({"service": name, "version": ver, "status": status})
                  
                  return status_report

          # ==========================================
          # 2. HYPERSCALE MONITOR (Í∞ÄÏÉÅ Î¶¨ÏÜåÏä§)
          # ==========================================
          class HyperscaleMonitor:
              def get_metrics(self):
                  return {
                      "cpu": psutil.cpu_percent(),
                      "ram": psutil.virtual_memory().percent,
                      "spec_cpu": "128 vCores",
                      "spec_ram": "512 GB"
                  }

          # ==========================================
          # 3. FINANCE & NEWS ENGINE
          # ==========================================
          class FinanceNewsEngine:
              def __init__(self):
                  self.feeds = {
                      "FIN_SHINHAN": "https://news.google.com/rss/search?q=Ïã†ÌïúÏùÄÌñâ+OR+Ïã†ÌïúÌà¨ÏûêÏ¶ùÍ∂å&hl=ko&gl=KR&ceid=KR:ko",
                      "FIN_HANA": "https://news.google.com/rss/search?q=ÌïòÎÇòÏùÄÌñâ+OR+ÌïòÎÇòÏ¶ùÍ∂å&hl=ko&gl=KR&ceid=KR:ko",
                      "KR_NAVER": "https://news.naver.com/main/rss/rss_flash.nhn",
                      "KR_SEC": "https://www.boannews.com/media/news_rss.xml"
                  }

              def fetch(self):
                  news_data = {}
                  corpus = []
                  for src, url in self.feeds.items():
                      entries = []
                      try:
                          f = feedparser.parse(url)
                          # Fallback logic omitted for brevity
                          for e in f.entries[:3]:
                              entries.append({"title": e.title, "link": e.link})
                              corpus.append(f"[{src}] {e.title}")
                      except: pass
                      news_data[src] = entries
                  return news_data, corpus

          # ==========================================
          # 4. AI COPILOT (RAG)
          # ==========================================
          class MegaCopilot:
              def __init__(self, corpus, farm_status):
                  self.kb = corpus
                  # Ïù∏ÌîÑÎùº ÏÉÅÌÉú ÏßÄÏãù Ï£ºÏûÖ
                  infra_text = "INFRASTRUCTURE STATUS: " + ", ".join([f"{s['service']} is {s['status']}" for s in farm_status])
                  self.kb.append(infra_text)

              def generate(self, query):
                  if not self.kb: return "Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ïã§Ìå®"
                  
                  vec = TfidfVectorizer()
                  mat = vec.fit_transform(self.kb)
                  q_vec = vec.transform([query])
                  sim = cosine_similarity(q_vec, mat).flatten()
                  
                  # ÏÉÅÏúÑ 4Í∞ú
                  indices = sim.argsort()[:-5:-1]
                  context = [self.kb[i] for i in indices if sim[i] > 0.05]
                  
                  timestamp = datetime.datetime.now().strftime("%H:%M")
                  res = f"### ü§ñ Mega-Copilot Answer ({timestamp})\n> **Q:** \"{query}\"\n\n"
                  
                  if context:
                      res += "**‚úÖ AI Analysis & Findings:**\n" + "\n".join([f"- {c}" for c in context])
                  else:
                      res += "‚ùå Í¥ÄÎ†® Ï†ïÎ≥¥Î•º ÏµúÏã† Îç∞Ïù¥ÌÑ∞ÏóêÏÑú Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§."
                  return res

          # ==========================================
          # 5. DASHBOARD
          # ==========================================
          class DashboardEngine:
              def draw_bar(self, val):
                  fill = int((val/100)*10)
                  return "‚ñà"*fill + "‚ñë"*(10-fill)

              def create(self, metrics, farm, news, copilot):
                  with open(DASH_PATH, 'w', encoding='utf-8') as f:
                      f.write(f"# üèóÔ∏è Grand Ops Mega-Infrastructure Dashboard\n")
                      f.write(f"> **Time:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')} (KST) | **System:** Upgraded & Secure\n\n")

                      # Copilot
                      f.write(f"{copilot}\n\n---\n")

                      # 1. Server Farm Status (NEW)
                      f.write("### üèóÔ∏è Enterprise Server Farm Status\n")
                      f.write("| Service | Version Detected | Status | Last Upgrade |\n|---|---|---|---|\n")
                      today = datetime.datetime.now().strftime('%Y-%m-%d')
                      for s in farm:
                          # Î≤ÑÏ†Ñ Î¨∏ÏûêÏó¥ Ï†ïÎ¶¨
                          ver_short = s['version'][:40] + "..." if len(s['version']) > 40 else s['version']
                          f.write(f"| **{s['service']}** | `{ver_short}` | {s['status']} | {today} |\n")
                      f.write("\n")

                      # 2. Finance News
                      f.write("### üè¶ Major Finance (Shinhan & Hana)\n")
                      f.write("| Group | Latest Headlines |\n|---|---|\n")
                      
                      shinhan = news.get('FIN_SHINHAN', [])
                      if shinhan:
                          f.write("| **üîµ Shinhan** | ")
                          for n in shinhan[:2]: f.write(f"‚Ä¢ [{n['title']}]({n['link']})<br>")
                          f.write(" |\n")

                      hana = news.get('FIN_HANA', [])
                      if hana:
                          f.write("| **üü¢ Hana** | ")
                          for n in hana[:2]: f.write(f"‚Ä¢ [{n['title']}]({n['link']})<br>")
                          f.write(" |\n")
                      f.write("\n")

                      # 3. System
                      f.write("### ‚ö° Hyperscale Metrics\n")
                      f.write(f"- **vCPU:** `{metrics['spec_cpu']}` (Load: {metrics['cpu']}%) `{self.draw_bar(metrics['cpu'])}`\n")
                      f.write(f"- **RAM:** `{metrics['spec_ram']}` (Used: {metrics['ram']}%) `{self.draw_bar(metrics['ram'])}`\n")

                      f.write("\n---\n*Powered by Grand Ops Mega-Infra v31.0*")

          def main():
              if not os.path.exists("data"): os.makedirs("data")
              conn = sqlite3.connect(DB_PATH)
              
              # 1. Ïù∏ÌîÑÎùº Ï†êÍ≤Ä (Upgrade Check)
              infra_mgr = ServerFarmManager()
              farm_status = infra_mgr.get_farm_status()
              
              # 2. ÏãúÏä§ÌÖú & Îâ¥Ïä§ ÏàòÏßë
              hs = HyperscaleMonitor()
              metrics = hs.get_metrics()
              
              news_engine = FinanceNewsEngine()
              news_data, corpus = news_engine.fetch()
              
              # 3. AI Î∂ÑÏÑù
              copilot = MegaCopilot(corpus, farm_status)
              ans = copilot.generate(USER_QUERY)
              
              # 4. ÎåÄÏãúÎ≥¥Îìú
              dash = DashboardEngine()
              dash.create(metrics, farm_status, news_data, ans)
              
              conn.close()
              print("‚úÖ Mega-Infra Provisioning & Reporting Done.")

          if __name__ == "__main__":
              main()
          EOF

      - name: üöÄ Run Mega-Infra Engine
        run: python scripts/mega_core.py

      - name: üì¢ Publish Dashboard
        run: cat "$DASHBOARD_FILE" >> $GITHUB_STEP_SUMMARY

      - name: üîí Encrypt & Sync
        run: |
          zip -e -P "$ARTIFACT_PASSWORD" mega_backup.zip data/*.md data/*.db
          
          git config --global user.name "Infra-Admin"
          git config --global user.email "admin@grand-ops.ai"
          git config --global --add safe.directory $GITHUB_WORKSPACE
          
          [ -f "$DASHBOARD_FILE" ] && git add -f "$DASHBOARD_FILE"
          [ -f "$DB_PATH" ] && git add -f "$DB_PATH"
          git add -A
          
          if [ -z "$(git status --porcelain)" ]; then exit 0; fi
          git commit -m "infra: mass server provision & upgrade [skip ci]"
          git push origin main || echo "Sync skipped"
