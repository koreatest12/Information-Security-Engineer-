name: ğŸ§  Grand Ops AI-Core Pipeline v15 (ML & Anomaly Detection)

on:
  schedule:
    - cron: '*/10 * * * *' # 10ë¶„ë§ˆë‹¤ AI ëª¨ë¸ í•™ìŠµ ë° ì¶”ë¡ 
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}
  cancel-in-progress: false

env:
  TZ: 'Asia/Seoul'
  DB_PATH: 'data/grand_ops_secure.db'
  REPORT_PATH: 'data/ai_threat_report.md'
  MODEL_PATH: 'data/anomaly_model.pkl'
  BACKUP_DIR: 'backup'
  ARTIFACT_PASSWORD: ${{ secrets.ARTIFACT_KEY || 'AI_Core_Secure_2025' }}

permissions:
  contents: write

jobs:
  # AI ì—”ì§„ êµ¬ë™ ë° ì¸í…”ë¦¬ì „ìŠ¤ ë¶„ì„ Job
  ai-copilot-engine:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # 1. AI êµ¬ë™ì„ ìœ„í•œ ê³ ì„±ëŠ¥ í™˜ê²½ êµ¬ì¶•
      - name: ğŸ—ï¸ Setup AI Infrastructure
        run: |
          echo "ğŸ§¬ Initializing AI Environment..."
          mkdir -p data backup config scripts
          
          # íŒŒì´ì¬ ìµœì‹ í™”
          python -m pip install --upgrade pip
          
          # [í•µì‹¬] ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (Scikit-learn, Pandas, NumPy)
          echo "ğŸ“¦ Installing ML Dependencies..."
          echo -e "requests\npandas\nnumpy\nscikit-learn" > requirements.txt
          pip install -r requirements.txt
          
          echo "âœ… AI Libraries Installed."

      # 2. [Expert] ë¨¸ì‹ ëŸ¬ë‹ íƒ‘ì¬ Copilot ìŠ¤í¬ë¦½íŠ¸ ìƒì„± (AI Factory)
      # 'EOF'ì— ë”°ì˜´í‘œë¥¼ ë¶™ì—¬ Bash ë³€ìˆ˜ ì¹˜í™˜ì„ ë°©ì§€(Python ì½”ë“œ ì›ë³¸ ë³´ì¡´)
      - name: ğŸ§  Generate AI Copilot Script
        run: |
          cat <<'EOF' > scripts/ai_ops_copilot.py
          import sqlite3
          import os
          import datetime
          import random
          import json
          import pandas as pd
          import numpy as np
          from sklearn.ensemble import IsolationForest
          from sklearn.preprocessing import StandardScaler

          # ì„¤ì • ë¡œë“œ
          DB_PATH = os.getenv('DB_PATH', 'data/grand_ops_secure.db')
          REPORT_PATH = os.getenv('REPORT_PATH', 'data/ai_threat_report.md')

          class AIEngine:
              def __init__(self, conn):
                  self.conn = conn
                  self.model = IsolationForest(contamination=0.1, random_state=42)
                  self.scaler = StandardScaler()

              def generate_synthetic_data(self):
                  """AI í•™ìŠµì„ ìœ„í•œ ì´ˆê¸° ë°ì´í„°ê°€ ë¶€ì¡±í•  ê²½ìš° í•©ì„± ë°ì´í„° ìƒì„±"""
                  print("ğŸ§ª Generating synthetic training data...")
                  cursor = self.conn.cursor()
                  actions = ['LOGIN', 'LOGOUT', 'QUERY', 'UPDATE', 'DELETE', 'ADMIN_ACCESS']
                  risks = ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']
                  
                  # 100ê°œì˜ í•™ìŠµìš© ë¡œê·¸ ì£¼ì…
                  data = []
                  for _ in range(100):
                      act = random.choice(actions)
                      risk = random.choice(risks)
                      # 'DELETE'ë‚˜ 'CRITICAL'ì€ ì´ìƒì¹˜ë¡œ ê°„ì£¼ë  í™•ë¥ ì„ ë†’ì´ê¸° ìœ„í•´ íŠ¹ì • íŒ¨í„´ ë¶€ì—¬ ê°€ëŠ¥
                      val = random.randint(1, 100) 
                      data.append((act, risk, val))
                  
                  cursor.executemany("INSERT INTO security_logs (action, risk_level, execution_time_ms) VALUES (?, ?, ?)", data)
                  self.conn.commit()

              def train_and_predict(self):
                  """ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ë¹„ì •ìƒ í–‰ìœ„(Anomaly) íƒì§€"""
                  print("ğŸ§  Training AI Model (Isolation Forest)...")
                  
                  # Pandasë¡œ ë°ì´í„° ë¡œë“œ
                  df = pd.read_sql_query("SELECT id, action, risk_level, execution_time_ms FROM security_logs", self.conn)
                  
                  if len(df) < 50:
                      self.generate_synthetic_data()
                      df = pd.read_sql_query("SELECT id, action, risk_level, execution_time_ms FROM security_logs", self.conn)

                  # Feature Engineering (ë¬¸ìì—´ -> ìˆ˜ì¹˜í™”)
                  df['action_code'] = df['action'].astype('category').cat.codes
                  df['risk_code'] = df['risk_level'].astype('category').cat.codes
                  
                  features = df[['action_code', 'risk_code', 'execution_time_ms']]
                  
                  # ëª¨ë¸ í•™ìŠµ
                  self.model.fit(features)
                  
                  # ì˜ˆì¸¡ (-1: ì´ìƒì¹˜/ê³µê²©ì˜ì‹¬, 1: ì •ìƒ)
                  df['anomaly_score'] = self.model.predict(features)
                  df['score_val'] = self.model.decision_function(features)
                  
                  anomalies = df[df['anomaly_score'] == -1]
                  return anomalies, len(df)

          def init_db():
              conn = sqlite3.connect(DB_PATH)
              cursor = conn.cursor()
              cursor.execute('''
                  CREATE TABLE IF NOT EXISTS security_logs (
                      id INTEGER PRIMARY KEY AUTOINCREMENT,
                      action TEXT,
                      risk_level TEXT,
                      execution_time_ms INTEGER,
                      timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                  )
              ''')
              conn.commit()
              return conn

          def main():
              print("ğŸš€ AI Copilot System v15.0 Initiated.")
              
              # ë””ë ‰í† ë¦¬ í™•ì¸
              if not os.path.exists("data"): os.makedirs("data")
              
              conn = init_db()
              ai_engine = AIEngine(conn)
              
              # ë¶„ì„ ì‹¤í–‰
              anomalies, total_count = ai_engine.train_and_predict()
              
              print(f"ğŸ“Š Analysis Complete. Scanned {total_count} logs.")
              print(f"ğŸš¨ Anomalies Detected: {len(anomalies)}")
              
              # ë¦¬í¬íŠ¸ ì‘ì„±
              with open(REPORT_PATH, "w", encoding="utf-8") as f:
                  f.write("# ğŸ§  AI Threat Intelligence Report\n")
                  f.write(f"**Generated At:** {datetime.datetime.now()}\n\n")
                  f.write("## ğŸ“Š AI Analysis Summary\n")
                  f.write(f"- **Total Data Points Scanned:** {total_count}\n")
                  f.write(f"- **Algorithm Used:** Isolation Forest (Unsupervised Learning)\n")
                  f.write(f"- **Threats Detected:** {len(anomalies)}\n\n")
                  
                  if not anomalies.empty:
                      f.write("## ğŸš¨ Detected Anomalies (Potential Threats)\n")
                      f.write("| ID | Action | Risk | Exec Time (ms) | Severity Score |\n")
                      f.write("|---|---|---|---|---|\n")
                      for _, row in anomalies.iterrows():
                          f.write(f"| {row['id']} | {row['action']} | {row['risk_level']} | {row['execution_time_ms']} | {row['score_val']:.4f} |\n")
                  else:
                      f.write("## âœ… System Status: CLEAN\n")
                      f.write("AI detected no significant anomalies in the current dataset.\n")

              conn.close()
              print("âœ… AI Tasks Completed Successfully.")

          if __name__ == "__main__":
              main()
          EOF
          
          echo "âœ¨ AI Copilot Script Generated."

      # 3. AI ì‹¤í–‰ (í•™ìŠµ ë° ì¶”ë¡  ìˆ˜í–‰)
      - name: ğŸš€ Run AI Inference
        run: |
          python scripts/ai_ops_copilot.py
          
          echo "ğŸ“„ Checking Generated Report:"
          cat data/ai_threat_report.md

      # 4. ê²°ê³¼ë¬¼ ì•”í˜¸í™” ë° ë°±ì—… (ê¸°ì¡´ ë³´ì•ˆ ë¡œì§ ìœ ì§€)
      - name: ğŸ”’ Encrypt & Backup
        run: |
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          cp "$DB_PATH" "$BACKUP_DIR/db_$TIMESTAMP.bak"
          
          echo "ğŸ” Encrypting AI Data..."
          zip -e -P "$ARTIFACT_PASSWORD" ai_secure_package.zip data/* config/* backup/*
          
          # ë°±ì—… ì •ë¦¬
          cd "$BACKUP_DIR" && ls -t *.bak | tail -n +6 | xargs -r rm --

      - name: Upload AI Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ai-intelligence-data
          path: ai_secure_package.zip
          retention-days: 1

      # 5. ì¸í…”ë¦¬ì „ìŠ¤ ë¦¬í¬íŠ¸ ë™ê¸°í™” (Git Commit)
      - name: ğŸ”„ Sync Intelligence Data
        run: |
          git config --global user.name "AI-Copilot-Bot"
          git config --global user.email "ai-core@grand-ops.io"
          git config --global --add safe.directory $GITHUB_WORKSPACE

          echo "ğŸ“¦ Staging AI Reports..."
          
          # íŒŒì¼ ì¡´ì¬ ì‹œ ê°•ì œ ì¶”ê°€
          [ -f "data/grand_ops_secure.db" ] && git add -f data/grand_ops_secure.db
          [ -f "data/ai_threat_report.md" ] && git add -f data/ai_threat_report.md
          
          git add -A

          if [ -z "$(git status --porcelain)" ]; then
             echo "âœ… Intelligence is up-to-date."
             exit 0
          fi

          echo "ğŸ’¾ Committing AI Analysis..."
          git commit -m "ai: anomaly detection report & model update [skip ci]"

          # Retry Loop
          MAX_RETRIES=5
          COUNT=0
          while [ $COUNT -lt $MAX_RETRIES ]; do
            git pull --rebase origin main || git rebase --abort
            if git push origin main; then
              echo "ğŸš€ AI Data Synced!"
              exit 0
            fi
            sleep 5
            COUNT=$((COUNT+1))
          done
          
          exit 1
