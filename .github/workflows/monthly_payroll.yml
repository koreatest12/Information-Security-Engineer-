name: Enterprise CTMFW & Vertica Batch System

on:
  schedule:
    - cron: '0 9 11,21 * *'
  workflow_dispatch:

jobs:
  run-ctm-system:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
      checks: write

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Dependencies
      run: |
        pip install pandas matplotlib reportlab openpyxl numpy cryptography tabulate schedule

    - name: Generate Enterprise CTMFW Script
      run: |
        cat << 'EOF' > enterprise_ctmfw.py
        import sqlite3
        import pandas as pd
        import os
        import time
        import shutil
        import schedule
        import numpy as np
        import hashlib
        from datetime import datetime
        from cryptography.fernet import Fernet
        from tabulate import tabulate

        # ==========================================
        # 1. Configuration & Directories
        # ==========================================
        DIR_INBOUND = "DATA_INBOUND"   # ëŒ€ì™¸ê³„ íŒŒì¼ ìˆ˜ì‹  í´ë”
        DIR_ARCHIVE = "DATA_ARCHIVE"   # ì²˜ë¦¬ ì™„ë£Œ íŒŒì¼ ë³´ê´€
        DIR_REPORTS = "BATCH_REPORTS"  # ê²°ê³¼ ë¦¬í¬íŠ¸

        for d in [DIR_INBOUND, DIR_ARCHIVE, DIR_REPORTS]:
            if not os.path.exists(d): os.makedirs(d)

        # ==========================================
        # 2. Security & Utils
        # ==========================================
        class SecurityManager:
            def __init__(self):
                self.key = Fernet.generate_key()
                self.cipher = Fernet(self.key)
            def hash_data(self, data): return hashlib.sha256(str(data).encode()).hexdigest()

        # ==========================================
        # 3. Vertica DW Manager (Mock)
        # ==========================================
        class VerticaDWManager:
            def __init__(self, db_name="vertica_dw.db"):
                self.conn = sqlite3.connect(db_name)
                self.cursor = self.conn.cursor()
                self.sec = SecurityManager()
                self._init_schema()

            def _init_schema(self):
                # Fact Table (ê±°ë˜ë‚´ì—­)
                self.cursor.execute('''CREATE TABLE IF NOT EXISTS fact_transactions (
                    tx_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    file_name TEXT,
                    tx_time TIMESTAMP,
                    sender TEXT,
                    amount INTEGER,
                    tx_hash TEXT
                )''')
                
                # Batch Log (ë°°ì¹˜ ìˆ˜í–‰ ì´ë ¥)
                self.cursor.execute('''CREATE TABLE IF NOT EXISTS sys_batch_log (
                    job_id TEXT,
                    start_time TIMESTAMP,
                    status TEXT,
                    message TEXT
                )''')
                self.conn.commit()

            def load_data_from_file(self, file_path):
                """[Loader] íŒŒì¼ì„ ì½ì–´ Bulk Insert ìˆ˜í–‰"""
                filename = os.path.basename(file_path)
                print(f"   >> [DB Load] Loading file: {filename}")
                
                # CSV íŒŒì¼ íŒŒì‹± ì‹œë®¬ë ˆì´ì…˜
                try:
                    df = pd.read_csv(file_path)
                    data_to_insert = []
                    for _, row in df.iterrows():
                        tx_hash = self.sec.hash_data(f"{row['sender']}{row['amount']}")
                        data_to_insert.append((filename, datetime.now(), row['sender'], row['amount'], tx_hash))
                    
                    self.cursor.executemany("""
                        INSERT INTO fact_transactions (file_name, tx_time, sender, amount, tx_hash)
                        VALUES (?, ?, ?, ?, ?)
                    """, data_to_insert)
                    self.conn.commit()
                    return True
                except Exception as e:
                    print(f"   !! [DB Error] {e}")
                    return False

            def log_job(self, job_name, status, msg):
                self.cursor.execute("INSERT INTO sys_batch_log VALUES (?, datetime('now'), ?, ?)", 
                                    (job_name, status, msg))
                self.conn.commit()

        # ==========================================
        # 4. External Interface (File Generator)
        # ==========================================
        class ExternalInterfaceSimulator:
            """ëŒ€ì™¸ê³„ ì‹œìŠ¤í…œ: ëœë¤í•˜ê²Œ íŠ¸ëœì­ì…˜ íŒŒì¼ì„ ìƒì„±í•˜ì—¬ Inboundì— ì „ì†¡"""
            def generate_transfer_file(self):
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"TX_DATA_{timestamp}.csv"
                filepath = os.path.join(DIR_INBOUND, filename)
                
                # ë°ì´í„° ìƒì„±
                cnt = np.random.randint(5, 15)
                data = {
                    'sender': [f"User_{np.random.randint(100,999)}" for _ in range(cnt)],
                    'amount': np.random.randint(1000, 50000, size=cnt) * 10
                }
                pd.DataFrame(data).to_csv(filepath, index=False)
                print(f"\n[Interface] ğŸ“¡ ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ íŒŒì¼ ì „ì†¡ë¨: {filename} ({cnt} rows)")

        # ==========================================
        # 5. CTMFW (Control-M File Watcher)
        # ==========================================
        class CTMFW_Service:
            """íŒŒì¼ ê°ì§€ ë° ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°"""
            def __init__(self, dw_mgr):
                self.dw = dw_mgr

            def watch_and_trigger(self):
                # Inbound í´ë” ìŠ¤ìº”
                files = [f for f in os.listdir(DIR_INBOUND) if f.endswith('.csv')]
                
                if not files:
                    return # íŒŒì¼ ì—†ìœ¼ë©´ ëŒ€ê¸°
                
                print(f"[CTMFW] ğŸ‘ï¸ íŒŒì¼ ê°ì§€ë¨: {len(files)}ê±´. ë°°ì¹˜ íŠ¸ë¦¬ê±° ê°€ë™.")
                
                for f in files:
                    src_path = os.path.join(DIR_INBOUND, f)
                    
                    # 1. íŒŒì¼ ì•ˆì •ì„± ì²´í¬ (CTMFW í•µì‹¬ ê¸°ëŠ¥: íŒŒì¼ ì‚¬ì´ì¦ˆ ë³€ë™ í™•ì¸ ë“±)
                    # ì—¬ê¸°ì„  ì¦‰ì‹œ ì²˜ë¦¬ë¡œ ê°€ì •
                    
                    # 2. DB Loader íŠ¸ë¦¬ê±°
                    success = self.dw.load_data_from_file(src_path)
                    
                    # 3. í›„ì²˜ë¦¬ (Archive ì´ë™)
                    if success:
                        dst_path = os.path.join(DIR_ARCHIVE, f)
                        shutil.move(src_path, dst_path)
                        self.dw.log_job("CTMFW_JOB", "SUCCESS", f"Processed {f}")
                        print(f"   >> [CTMFW] Job Triggered & File Archived: {f}")
                    else:
                        self.dw.log_job("CTMFW_JOB", "FAIL", f"Error {f}")

        # ==========================================
        # 6. BS & MIS Batch Engine
        # ==========================================
        class EnterpriseBatchEngine:
            def __init__(self, dw_mgr):
                self.dw = dw_mgr

            def run_bs_batch(self):
                """ëŒ€ì°¨ëŒ€ì¡°í‘œ(BS) ìƒì„±"""
                print("[Batch] ğŸ“Š BS(ì¬ë¬´ìƒíƒœí‘œ) ê²°ì‚° ì‘ì—… ìˆ˜í–‰...")
                df = pd.read_sql("SELECT sum(amount) as total FROM fact_transactions", self.dw.conn)
                total_assets = df.iloc[0]['total'] if df.iloc[0]['total'] else 0
                
                report_file = os.path.join(DIR_REPORTS, f"BS_Report_{datetime.now().strftime('%H%M')}.txt")
                with open(report_file, "w") as f:
                    f.write(f"=== BALANCE SHEET ({datetime.now()}) ===\n")
                    f.write(f"Total Assets (Cash In): {total_assets:,} KRW\n")
                    f.write(f"Liabilities: 0\n")
                    f.write(f"Equity: {total_assets:,}\n")
                
                self.dw.log_job("BS_BATCH", "SUCCESS", f"Total Asset: {total_assets}")

            def run_mis_batch(self):
                """ê²½ì˜ì •ë³´(MIS) ë¶„ì„"""
                print("[Batch] ğŸ“ˆ MIS(ê²½ì˜ë¶„ì„) ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
                query = """
                    SELECT substr(tx_time, 1, 13) as hour, count(*) as cnt, sum(amount) as amt 
                    FROM fact_transactions GROUP BY hour
                """
                df = pd.read_sql(query, self.dw.conn)
                if not df.empty:
                    print(tabulate(df, headers=['Hour', 'Count', 'Amount'], tablefmt='psql'))
                self.dw.log_job("MIS_BATCH", "SUCCESS", "MIS Reported")

        # ==========================================
        # 7. Resident Daemon (Orchestrator)
        # ==========================================
        if __name__ == "__main__":
            print(">> [System] ì—”í„°í”„ë¼ì´ì¦ˆ ë°°ì¹˜ ì‹œìŠ¤í…œ ê°€ë™ (Vertica + CTMFW)")
            
            # ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
            dw = VerticaDWManager()
            interface = ExternalInterfaceSimulator()
            ctmfw = CTMFW_Service(dw)
            batch = EnterpriseBatchEngine(dw)
            
            # ìŠ¤ì¼€ì¤„ë§ ë“±ë¡
            # 1. ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤: 5ì´ˆë§ˆë‹¤ íŒŒì¼ ì „ì†¡ (ì‹œë®¬ë ˆì´ì…˜)
            schedule.every(5).seconds.do(interface.generate_transfer_file)
            
            # 2. CTMFW: 1ì´ˆë§ˆë‹¤ í´ë” ê°ì‹œ (Real-time Watcher)
            schedule.every(1).seconds.do(ctmfw.watch_and_trigger)
            
            # 3. BS/MIS ë°°ì¹˜: 10ì´ˆë§ˆë‹¤ ê²°ì‚° (20ë¶„ ê°„ê²© ì‹œë®¬ë ˆì´ì…˜)
            schedule.every(10).seconds.do(batch.run_bs_batch)
            schedule.every(10).seconds.do(batch.run_mis_batch)
            
            # ë°ëª¬ ì‹¤í–‰ ë£¨í”„ (GitHub Actions íƒ€ì„ì•„ì›ƒ ë°©ì§€: 40ì´ˆ ì‹¤í–‰)
            start = time.time()
            while time.time() - start < 40:
                schedule.run_pending()
                time.sleep(1)
            
            print(">> [System] ë°°ì¹˜ ìœˆë„ìš° ì¢…ë£Œ. ì‹œìŠ¤í…œ ì˜¤í”„ë¼ì¸.")
        EOF

    - name: Run Enterprise System
      run: python enterprise_ctmfw.py

    - name: Upload Reports
      uses: actions/upload-artifact@v4
      with:
        name: Enterprise-Reports-${{ github.run_id }}
        path: |
          BATCH_REPORTS/
          DATA_ARCHIVE/
        retention-days: 30
