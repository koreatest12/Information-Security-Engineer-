name: Total Financial Control-M Batch System

on:
  schedule:
    - cron: '0 9 11,21 * *' # ì›”ê¸‰ì¼ ë“± ì£¼ìš” ì¼ì
  workflow_dispatch:        # ìˆ˜ë™ ì‹¤í–‰

jobs:
  run-enterprise-control-m:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      actions: read
      checks: write

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'

    - name: Install Dependencies
      run: |
        pip install pandas matplotlib reportlab openpyxl numpy cryptography tabulate schedule

    # [í•µì‹¬] scripts í´ë”ì— ì´ˆëŒ€í˜• ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
    - name: Generate Control-M System Script
      run: |
        mkdir -p scripts
        cat << 'EOF' > scripts/financial_ctm_system.py
        import sqlite3
        import pandas as pd
        import os
        import time
        import shutil
        import schedule
        import numpy as np
        import hashlib
        from datetime import datetime
        from cryptography.fernet import Fernet
        from tabulate import tabulate

        # ==========================================
        # 1. Environment & Paths (Root Based)
        # ==========================================
        BASE_DIR = os.getcwd()
        DIRS = {
            'INBOUND': os.path.join(BASE_DIR, 'INBOUND'),
            'ARCHIVE': os.path.join(BASE_DIR, 'DATA/ARCHIVE'),
            'BACKUP': os.path.join(BASE_DIR, 'DATA/BACKUP'),
            'REPORT': os.path.join(BASE_DIR, 'DATA/REPORT'),
            'LOGS': os.path.join(BASE_DIR, 'DATA/LOGS')
        }
        # ë„ë©”ì¸ë³„ í´ë” ì •ì˜
        DOMAINS = ['CORE', 'LOAN', 'CARD', 'STOCK', 'FOREX']
        for d in DIRS.values():
            if not os.path.exists(d): os.makedirs(d)
        for dom in DOMAINS:
            p = os.path.join(DIRS['INBOUND'], dom)
            if not os.path.exists(p): os.makedirs(p)

        # ==========================================
        # 2. Security (AES-256)
        # ==========================================
        class SecurityManager:
            def __init__(self):
                self.key = Fernet.generate_key()
                self.cipher = Fernet(self.key)
            def encrypt(self, text): return self.cipher.encrypt(str(text).encode()).decode()
            def decrypt(self, text): return self.cipher.decrypt(str(text).encode()).decode()
            def get_hash(self, text): return hashlib.sha256(str(text).encode()).hexdigest()

        # ==========================================
        # 3. Enterprise DW & Ledger
        # ==========================================
        class EnterpriseDW:
            def __init__(self, db_name="enterprise_dw.db"):
                self.db_path = os.path.join(BASE_DIR, 'DATA', db_name)
                self.conn = sqlite3.connect(self.db_path)
                self.cursor = self.conn.cursor()
                self.sec = SecurityManager()
                self._init_schema()

            def _init_schema(self):
                # 1. í†µí•© ê±°ë˜ ì›ì¥ (General Ledger)
                self.cursor.execute('''CREATE TABLE IF NOT EXISTS fact_general_ledger (
                    tx_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    domain TEXT,       -- CORE, CARD, LOAN...
                    tx_type TEXT,
                    user_enc TEXT,
                    amount INTEGER,
                    tx_time TIMESTAMP,
                    tx_hash TEXT
                )''')

                # 2. Control-M Job History (AJF Simulation)
                self.cursor.execute('''CREATE TABLE IF NOT EXISTS ctm_job_history (
                    order_id INTEGER PRIMARY KEY AUTOINCREMENT,
                    job_name TEXT,
                    job_type TEXT,    -- FW(FileWatcher), CMD, DUMMY
                    start_time TIMESTAMP,
                    end_time TIMESTAMP,
                    status TEXT,      -- OK, NOTOK, EXECUTING
                    log_output TEXT
                )''')
                self.conn.commit()

            def insert_ledger(self, domain, tx_type, user, amount):
                enc_user = self.sec.encrypt(user)
                tx_hash = self.sec.get_hash(f"{domain}{user}{amount}{time.time()}")
                self.cursor.execute("""
                    INSERT INTO fact_general_ledger (domain, tx_type, user_enc, amount, tx_time, tx_hash)
                    VALUES (?, ?, ?, ?, datetime('now'), ?)
                """, (domain, tx_type, enc_user, amount, tx_hash))
                self.conn.commit()

            def execute_backup(self):
                ts = datetime.now().strftime('%Y%m%d_%H%M%S')
                bk_path = os.path.join(DIRS['BACKUP'], f"FULL_BACKUP_{ts}.db")
                try:
                    bck = sqlite3.connect(bk_path)
                    self.conn.backup(bck)
                    bck.close()
                    return True, bk_path
                except Exception as e:
                    return False, str(e)

        # ==========================================
        # 4. Interface Simulator (Multi-Domain)
        # ==========================================
        class InterfaceGen:
            def gen_files(self):
                # ê° ë„ë©”ì¸ë³„ ëœë¤ íŒŒì¼ ìƒì„±
                for dom in DOMAINS:
                    if np.random.random() > 0.7: # 30% í™•ë¥ ë¡œ íŒŒì¼ ìƒì„± (ë¹„ë™ê¸° ì‹œë®¬ë ˆì´ì…˜)
                        self._create_file(dom)

            def _create_file(self, domain):
                ts = datetime.now().strftime("%H%M%S")
                fname = f"{domain}_TX_{ts}.dat"
                fpath = os.path.join(DIRS['INBOUND'], domain, fname)
                
                cnt = np.random.randint(5, 20)
                data = {
                    'user': [f"User_{np.random.randint(100,999)}" for _ in range(cnt)],
                    'type': ['TRX_NORM' for _ in range(cnt)],
                    'amount': np.random.randint(10, 1000) * 1000
                }
                pd.DataFrame(data).to_csv(fpath, index=False)
                # print(f"ğŸ“¡ [IF] {domain} File Arrived: {fname}")

        # ==========================================
        # 5. Control-M Engine (The Core)
        # ==========================================
        class ControlM_Engine:
            """
            Control-Mì˜ Active Job File(AJF) ë° Condition ë¡œì§ ì‹œë®¬ë ˆì´ì…˜
            """
            def __init__(self, dw):
                self.dw = dw
                self.conditions = set() # Condition-Pool (ì„ í›„í–‰ ì œì–´ìš©)
                self.active_jobs = []

            def set_condition(self, cond_name):
                self.conditions.add(cond_name)
                # print(f"   [CTM] Condition Added: {cond_name}")

            def check_condition(self, cond_name):
                return cond_name in self.conditions

            def log_job(self, name, jtype, status, msg):
                self.dw.cursor.execute("""
                    INSERT INTO ctm_job_history (job_name, job_type, start_time, end_time, status, log_output)
                    VALUES (?, ?, datetime('now'), datetime('now'), ?, ?)
                """, (name, jtype, status, msg))
                self.dw.conn.commit()
                print(f"âš™ï¸ [CTM] Job Ended: {name} | Status: {status}")

            # --- Job Types ---
            
            def job_ctmfw(self, domain):
                """File Watcher Job"""
                job_name = f"FW_{domain}_WATCHER"
                watch_dir = os.path.join(DIRS['INBOUND'], domain)
                files = [f for f in os.listdir(watch_dir) if f.endswith('.dat')]
                
                if files:
                    # íŒŒì¼ ê°ì§€ ì„±ê³µ
                    for f in files:
                        src = os.path.join(watch_dir, f)
                        # ë°°ì¹˜ ì‘ì—… íŠ¸ë¦¬ê±° (Job Chain)
                        self.job_process_batch(domain, src)
                        
                        # ì²˜ë¦¬ í›„ Archive ì´ë™
                        dst = os.path.join(DIRS['ARCHIVE'], f"{domain}_{f}")
                        shutil.move(src, dst)
                    
                    self.set_condition(f"COND_{domain}_FILE_OK")
                    self.log_job(job_name, "CTMFW", "OK", f"Detected {len(files)} files")
                else:
                    # íŒŒì¼ ì—†ìŒ (Waiting)
                    pass 

            def job_process_batch(self, domain, filepath):
                """Data Load & Ledger Process Job"""
                job_name = f"BATCH_{domain}_LOADER"
                try:
                    df = pd.read_csv(filepath)
                    for _, row in df.iterrows():
                        self.dw.insert_ledger(domain, row['type'], row['user'], row['amount'])
                    
                    self.log_job(job_name, "CMD", "OK", f"Loaded {len(df)} rows")
                    
                    # í›„í–‰ ë°±ì—… Job íŠ¸ë¦¬ê±°ë¥¼ ìœ„í•œ ì¡°ê±´ ì„¤ì • (Trigger)
                    self.set_condition("COND_DATA_CHANGED")
                    
                except Exception as e:
                    self.log_job(job_name, "CMD", "NOTOK", str(e))

            def job_backup_cyclic(self):
                """DB Backup Job (Conditional)"""
                job_name = "JOB_DB_BACKUP"
                # ì¡°ê±´: ë°ì´í„° ë³€ê²½ì´ ê°ì§€ë˜ì—ˆì„ ë•Œë§Œ ìˆ˜í–‰
                if self.check_condition("COND_DATA_CHANGED"):
                    res, path = self.dw.execute_backup()
                    status = "OK" if res else "NOTOK"
                    self.log_job(job_name, "CMD", status, path)
                    
                    # ì¡°ê±´ ì´ˆê¸°í™” (ë‹¤ìŒ ë³€ê²½ ì‹œê¹Œì§€ ëŒ€ê¸°)
                    self.conditions.remove("COND_DATA_CHANGED")

            def job_day_close(self):
                """Daily Closing Job (ë§ˆê° ë°°ì¹˜)"""
                job_name = "JOB_DAY_CLOSE"
                # ëª¨ë“  ë„ë©”ì¸ì˜ íŒŒì¼ ì²˜ë¦¬ê°€ ìµœì†Œ 1íšŒ ì´ìƒ ë°œìƒí–ˆëŠ”ì§€ ì²´í¬
                # (ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œëŠ” Ledger ì§‘ê³„ë¡œ ëŒ€ì²´)
                print("\nğŸ [CTM] Executing Day Close Batch...")
                
                df = pd.read_sql("SELECT domain, sum(amount) as total FROM fact_general_ledger GROUP BY domain", self.dw.conn)
                if not df.empty:
                    print(tabulate(df, headers='keys', tablefmt='psql'))
                
                self.log_job(job_name, "DUMMY", "OK", "Day Close Complete")

        # ==========================================
        # 6. Main Flow (Scheduler)
        # ==========================================
        if __name__ == "__main__":
            print(">> [System] Financial Control-M Engine Started (PID: {})".format(os.getpid()))
            
            dw = EnterpriseDW()
            ctm = ControlM_Engine(dw)
            igen = InterfaceGen()
            
            # --- Schedule Definition (Job Flow) ---
            
            # 1. Interface Simulator (ì™¸ë¶€ íŒŒì¼ ìˆ˜ì‹  ì‹œë®¬ë ˆì´ì…˜)
            schedule.every(2).seconds.do(igen.gen_files)
            
            # 2. File Watchers (5ê°œ ë„ë©”ì¸ ê°ì‹œ - ë³‘ë ¬ ìˆ˜í–‰)
            for dom in DOMAINS:
                schedule.every(1).seconds.do(ctm.job_ctmfw, domain=dom)
            
            # 3. Backup Job (Cyclic - ì¡°ê±´ë¶€ ìˆ˜í–‰)
            schedule.every(5).seconds.do(ctm.job_backup_cyclic)
            
            # 4. Monitoring Dashboard
            def show_dash():
                print(f"\n--- CTM AJF View ({datetime.now().strftime('%H:%M:%S')}) ---")
                df = pd.read_sql("SELECT job_name, status, end_time FROM ctm_job_history ORDER BY end_time DESC LIMIT 7", dw.conn)
                if not df.empty: print(tabulate(df, headers='keys', tablefmt='plain'))
            schedule.every(5).seconds.do(show_dash)

            # --- Execution Loop ---
            start_ts = time.time()
            RUN_DURATION = 60 # 60ì´ˆê°„ ì‹œë®¬ë ˆì´ì…˜
            
            try:
                while time.time() - start_ts < RUN_DURATION:
                    schedule.run_pending()
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
            
            # --- Day Close ---
            ctm.job_day_close()
            
            # Final Export
            print(">> [System] Saving Final Reports...")
            for t in ['fact_general_ledger', 'ctm_job_history']:
                pd.read_sql(f"SELECT * FROM {t}", dw.conn).to_excel(f"{DIRS['REPORT']}/{t}.xlsx")
            print(">> [System] Shutdown Gracefully.")
        EOF

    # ìƒì„±ëœ scripts í´ë” ë‚´ì˜ íŒŒì¼ ì‹¤í–‰
    - name: Run Control-M Engine
      run: python scripts/financial_ctm_system.py

    - name: Upload Logs & Reports
      uses: actions/upload-artifact@v4
      with:
        name: ControlM-Financial-Data-${{ github.run_id }}
        path: |
          DATA/REPORT/
          DATA/BACKUP/
          DATA/LOGS/
        retention-days: 30
